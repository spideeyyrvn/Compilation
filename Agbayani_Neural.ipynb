{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "oVj-bMYkL2Lq"
   },
   "outputs": [],
   "source": [
    "#Import Libraries\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from torchvision.utils import save_image\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_bBKIZwIL-Ve"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\raven\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\raven\\anaconda3\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "#Load the base model\n",
    "model=models.vgg19(pretrained=True).features\n",
    "#Assign the variable device\n",
    "device=torch.device(\"cuda\" if (torch.cuda.is_available()) else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CsLVSQhQMOEv"
   },
   "outputs": [],
   "source": [
    "#Define the function\n",
    "def image_loader(path):\n",
    "    image=Image.open(path)\n",
    "    loader=transforms.Compose([transforms.Resize((512,512)), transforms.ToTensor()])\n",
    "    image=loader(image).unsqueeze(0)\n",
    "    return image.to(device,torch.float)\n",
    "\n",
    "#Load the base photo and the style image\n",
    "original_image=image_loader('C:/Users/raven/Downloads/pics/Technological_Institute_of_the_Philippines_Quezon_City.jpg')\n",
    "style_image=image_loader('C:/Users/raven/Downloads/pics/Bataan.jpg')\n",
    "\n",
    "#Create the generated image \n",
    "generated_image=original_image.clone().requires_grad_(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "K__9-dI2MX42"
   },
   "outputs": [],
   "source": [
    "#Define the class model\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG,self).__init__()\n",
    "        self.req_features= ['0','5','10','19','28'] \n",
    "        self.model=models.vgg19(pretrained=True).features[:29] \n",
    "   \n",
    "    def forward(self,x):\n",
    "        features=[]\n",
    "        for layer_num,layer in enumerate(self.model):\n",
    "            x=layer(x)\n",
    "            if (str(layer_num) in self.req_features):\n",
    "                features.append(x)\n",
    "                \n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "j-CpgXBYMcfu"
   },
   "outputs": [],
   "source": [
    "def calc_content_loss(gen_feat,orig_feat):\n",
    "    content_l=torch.mean((gen_feat-orig_feat)**2)\n",
    "    return content_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "3Mik9SYNMfd-"
   },
   "outputs": [],
   "source": [
    "def calc_style_loss(gen,style):\n",
    "    batch_size,channel,height,width=gen.shape\n",
    "\n",
    "    G=torch.mm(gen.view(channel,height*width),gen.view(channel,height*width).t())\n",
    "    A=torch.mm(style.view(channel,height*width),style.view(channel,height*width).t())\n",
    "        \n",
    "    style_l=torch.mean((G-A)**2)\n",
    "    return style_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "jwajac2wMifG"
   },
   "outputs": [],
   "source": [
    "def calculate_loss(gen_features, orig_feautes, style_featues):\n",
    "    style_loss=content_loss=0\n",
    "    for gen,cont,style in zip(gen_features,orig_feautes,style_featues):\n",
    "        content_loss+=calc_content_loss(gen,cont)\n",
    "        style_loss+=calc_style_loss(gen,style)\n",
    "    \n",
    "    total_loss=alpha*content_loss + beta*style_loss \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "J7vXTfU5Mk7X"
   },
   "outputs": [],
   "source": [
    "#Load the model\n",
    "model=VGG().to(device).eval() \n",
    "\n",
    "#Initialize the parameters that are needed\n",
    "epoch=7000\n",
    "lr=0.004\n",
    "alpha=8\n",
    "beta=70\n",
    "\n",
    "\n",
    "optimizer=optim.Adam([generated_image],lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "VkKlqIkFMn8m",
    "outputId": "7e347244-6033-4514-8786-681964cf7f6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7.9450e+09, grad_fn=<AddBackward0>)\n",
      "tensor(6.8384e+09, grad_fn=<AddBackward0>)\n",
      "tensor(6.1688e+09, grad_fn=<AddBackward0>)\n",
      "tensor(5.7265e+09, grad_fn=<AddBackward0>)\n",
      "tensor(5.4172e+09, grad_fn=<AddBackward0>)\n",
      "tensor(5.1842e+09, grad_fn=<AddBackward0>)\n",
      "tensor(4.9938e+09, grad_fn=<AddBackward0>)\n",
      "tensor(4.8290e+09, grad_fn=<AddBackward0>)\n",
      "tensor(4.6819e+09, grad_fn=<AddBackward0>)\n",
      "tensor(4.5483e+09, grad_fn=<AddBackward0>)\n",
      "tensor(4.4253e+09, grad_fn=<AddBackward0>)\n",
      "tensor(4.3114e+09, grad_fn=<AddBackward0>)\n",
      "tensor(4.2046e+09, grad_fn=<AddBackward0>)\n",
      "tensor(4.1038e+09, grad_fn=<AddBackward0>)\n",
      "tensor(4.0082e+09, grad_fn=<AddBackward0>)\n",
      "tensor(3.9173e+09, grad_fn=<AddBackward0>)\n",
      "tensor(3.8306e+09, grad_fn=<AddBackward0>)\n",
      "tensor(3.7475e+09, grad_fn=<AddBackward0>)\n",
      "tensor(3.6678e+09, grad_fn=<AddBackward0>)\n",
      "tensor(3.5914e+09, grad_fn=<AddBackward0>)\n",
      "tensor(3.5181e+09, grad_fn=<AddBackward0>)\n",
      "tensor(3.4477e+09, grad_fn=<AddBackward0>)\n",
      "tensor(3.3800e+09, grad_fn=<AddBackward0>)\n",
      "tensor(3.3149e+09, grad_fn=<AddBackward0>)\n",
      "tensor(3.2523e+09, grad_fn=<AddBackward0>)\n",
      "tensor(3.1921e+09, grad_fn=<AddBackward0>)\n",
      "tensor(3.1341e+09, grad_fn=<AddBackward0>)\n",
      "tensor(3.0782e+09, grad_fn=<AddBackward0>)\n",
      "tensor(3.0243e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.9722e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.9220e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.8733e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.8263e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.7807e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.7365e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.6936e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.6519e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.6113e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.5719e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.5334e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.4959e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.4593e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.4235e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.3885e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.3543e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.3208e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.2879e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.2557e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.2240e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.1929e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.1624e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.1323e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.1028e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.0737e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.0450e+09, grad_fn=<AddBackward0>)\n",
      "tensor(2.0167e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.9889e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.9614e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.9342e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.9074e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.8809e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.8547e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.8288e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.8031e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.7777e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.7526e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.7276e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.7030e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.6785e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.6543e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.6303e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.6065e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.5829e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.5596e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.5365e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.5136e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.4909e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.4684e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.4461e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.4241e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.4022e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.3806e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.3591e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.3379e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.3169e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.2960e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.2754e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.2549e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.2346e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.2145e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.1946e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.1749e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.1554e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.1362e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.1171e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.0982e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.0795e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.0610e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.0427e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.0246e+09, grad_fn=<AddBackward0>)\n",
      "tensor(1.0067e+09, grad_fn=<AddBackward0>)\n",
      "tensor(9.8899e+08, grad_fn=<AddBackward0>)\n",
      "tensor(9.7151e+08, grad_fn=<AddBackward0>)\n",
      "tensor(9.5423e+08, grad_fn=<AddBackward0>)\n",
      "tensor(9.3716e+08, grad_fn=<AddBackward0>)\n",
      "tensor(9.2030e+08, grad_fn=<AddBackward0>)\n",
      "tensor(9.0365e+08, grad_fn=<AddBackward0>)\n",
      "tensor(8.8721e+08, grad_fn=<AddBackward0>)\n",
      "tensor(8.7097e+08, grad_fn=<AddBackward0>)\n",
      "tensor(8.5495e+08, grad_fn=<AddBackward0>)\n",
      "tensor(8.3913e+08, grad_fn=<AddBackward0>)\n",
      "tensor(8.2353e+08, grad_fn=<AddBackward0>)\n",
      "tensor(8.0813e+08, grad_fn=<AddBackward0>)\n",
      "tensor(7.9295e+08, grad_fn=<AddBackward0>)\n",
      "tensor(7.7798e+08, grad_fn=<AddBackward0>)\n",
      "tensor(7.6322e+08, grad_fn=<AddBackward0>)\n",
      "tensor(7.4867e+08, grad_fn=<AddBackward0>)\n",
      "tensor(7.3433e+08, grad_fn=<AddBackward0>)\n",
      "tensor(7.2021e+08, grad_fn=<AddBackward0>)\n",
      "tensor(7.0629e+08, grad_fn=<AddBackward0>)\n",
      "tensor(6.9259e+08, grad_fn=<AddBackward0>)\n",
      "tensor(6.7909e+08, grad_fn=<AddBackward0>)\n",
      "tensor(6.6580e+08, grad_fn=<AddBackward0>)\n",
      "tensor(6.5272e+08, grad_fn=<AddBackward0>)\n",
      "tensor(6.3985e+08, grad_fn=<AddBackward0>)\n",
      "tensor(6.2718e+08, grad_fn=<AddBackward0>)\n",
      "tensor(6.1472e+08, grad_fn=<AddBackward0>)\n",
      "tensor(6.0246e+08, grad_fn=<AddBackward0>)\n",
      "tensor(5.9040e+08, grad_fn=<AddBackward0>)\n",
      "tensor(5.7855e+08, grad_fn=<AddBackward0>)\n",
      "tensor(5.6690e+08, grad_fn=<AddBackward0>)\n",
      "tensor(5.5544e+08, grad_fn=<AddBackward0>)\n",
      "tensor(5.4419e+08, grad_fn=<AddBackward0>)\n",
      "tensor(5.3313e+08, grad_fn=<AddBackward0>)\n",
      "tensor(5.2227e+08, grad_fn=<AddBackward0>)\n",
      "tensor(5.1160e+08, grad_fn=<AddBackward0>)\n",
      "tensor(5.0112e+08, grad_fn=<AddBackward0>)\n",
      "tensor(4.9083e+08, grad_fn=<AddBackward0>)\n",
      "tensor(4.8073e+08, grad_fn=<AddBackward0>)\n",
      "tensor(4.7082e+08, grad_fn=<AddBackward0>)\n",
      "tensor(4.6109e+08, grad_fn=<AddBackward0>)\n",
      "tensor(4.5154e+08, grad_fn=<AddBackward0>)\n",
      "tensor(4.4218e+08, grad_fn=<AddBackward0>)\n",
      "tensor(4.3299e+08, grad_fn=<AddBackward0>)\n",
      "tensor(4.2398e+08, grad_fn=<AddBackward0>)\n",
      "tensor(4.1515e+08, grad_fn=<AddBackward0>)\n",
      "tensor(4.0648e+08, grad_fn=<AddBackward0>)\n",
      "tensor(3.9799e+08, grad_fn=<AddBackward0>)\n",
      "tensor(3.8967e+08, grad_fn=<AddBackward0>)\n",
      "tensor(3.8151e+08, grad_fn=<AddBackward0>)\n",
      "tensor(3.7352e+08, grad_fn=<AddBackward0>)\n",
      "tensor(3.6569e+08, grad_fn=<AddBackward0>)\n",
      "tensor(3.5802e+08, grad_fn=<AddBackward0>)\n",
      "tensor(3.5051e+08, grad_fn=<AddBackward0>)\n",
      "tensor(3.4315e+08, grad_fn=<AddBackward0>)\n",
      "tensor(3.3595e+08, grad_fn=<AddBackward0>)\n",
      "tensor(3.2890e+08, grad_fn=<AddBackward0>)\n",
      "tensor(3.2199e+08, grad_fn=<AddBackward0>)\n",
      "tensor(3.1524e+08, grad_fn=<AddBackward0>)\n",
      "tensor(3.0863e+08, grad_fn=<AddBackward0>)\n",
      "tensor(3.0216e+08, grad_fn=<AddBackward0>)\n",
      "tensor(2.9583e+08, grad_fn=<AddBackward0>)\n",
      "tensor(2.8964e+08, grad_fn=<AddBackward0>)\n",
      "tensor(2.8359e+08, grad_fn=<AddBackward0>)\n",
      "tensor(2.7767e+08, grad_fn=<AddBackward0>)\n",
      "tensor(2.7188e+08, grad_fn=<AddBackward0>)\n",
      "tensor(2.6623e+08, grad_fn=<AddBackward0>)\n",
      "tensor(2.6069e+08, grad_fn=<AddBackward0>)\n",
      "tensor(2.5529e+08, grad_fn=<AddBackward0>)\n",
      "tensor(2.5001e+08, grad_fn=<AddBackward0>)\n",
      "tensor(2.4484e+08, grad_fn=<AddBackward0>)\n",
      "tensor(2.3980e+08, grad_fn=<AddBackward0>)\n",
      "tensor(2.3487e+08, grad_fn=<AddBackward0>)\n",
      "tensor(2.3006e+08, grad_fn=<AddBackward0>)\n",
      "tensor(2.2536e+08, grad_fn=<AddBackward0>)\n",
      "tensor(2.2077e+08, grad_fn=<AddBackward0>)\n",
      "tensor(2.1629e+08, grad_fn=<AddBackward0>)\n",
      "tensor(2.1191e+08, grad_fn=<AddBackward0>)\n",
      "tensor(2.0764e+08, grad_fn=<AddBackward0>)\n",
      "tensor(2.0347e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.9940e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.9543e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.9156e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.8778e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.8409e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.8049e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.7698e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.7355e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.7021e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.6696e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.6378e+08, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.6069e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.5767e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.5472e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.5185e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.4906e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.4633e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.4368e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.4109e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.3857e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.3611e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.3371e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.3138e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.2910e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.2689e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.2473e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.2262e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.2058e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.1858e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.1663e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.1474e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.1290e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.1110e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.0935e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.0764e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.0598e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.0436e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.0278e+08, grad_fn=<AddBackward0>)\n",
      "tensor(1.0124e+08, grad_fn=<AddBackward0>)\n",
      "tensor(99747560., grad_fn=<AddBackward0>)\n",
      "tensor(98288800., grad_fn=<AddBackward0>)\n",
      "tensor(96867336., grad_fn=<AddBackward0>)\n",
      "tensor(95482408., grad_fn=<AddBackward0>)\n",
      "tensor(94132784., grad_fn=<AddBackward0>)\n",
      "tensor(92817808., grad_fn=<AddBackward0>)\n",
      "tensor(91536480., grad_fn=<AddBackward0>)\n",
      "tensor(90287584., grad_fn=<AddBackward0>)\n",
      "tensor(89070600., grad_fn=<AddBackward0>)\n",
      "tensor(87884608., grad_fn=<AddBackward0>)\n",
      "tensor(86728640., grad_fn=<AddBackward0>)\n",
      "tensor(85602136., grad_fn=<AddBackward0>)\n",
      "tensor(84504176., grad_fn=<AddBackward0>)\n",
      "tensor(83433760., grad_fn=<AddBackward0>)\n",
      "tensor(82390176., grad_fn=<AddBackward0>)\n",
      "tensor(81372752., grad_fn=<AddBackward0>)\n",
      "tensor(80380792., grad_fn=<AddBackward0>)\n",
      "tensor(79413136., grad_fn=<AddBackward0>)\n",
      "tensor(78469560., grad_fn=<AddBackward0>)\n",
      "tensor(77549320., grad_fn=<AddBackward0>)\n",
      "tensor(76651824., grad_fn=<AddBackward0>)\n",
      "tensor(75776328., grad_fn=<AddBackward0>)\n",
      "tensor(74922256., grad_fn=<AddBackward0>)\n",
      "tensor(74088984., grad_fn=<AddBackward0>)\n",
      "tensor(73275768., grad_fn=<AddBackward0>)\n",
      "tensor(72482032., grad_fn=<AddBackward0>)\n",
      "tensor(71707520., grad_fn=<AddBackward0>)\n",
      "tensor(70951384., grad_fn=<AddBackward0>)\n",
      "tensor(70213120., grad_fn=<AddBackward0>)\n",
      "tensor(69492128., grad_fn=<AddBackward0>)\n",
      "tensor(68788112., grad_fn=<AddBackward0>)\n",
      "tensor(68100488., grad_fn=<AddBackward0>)\n",
      "tensor(67428496., grad_fn=<AddBackward0>)\n",
      "tensor(66772140., grad_fn=<AddBackward0>)\n",
      "tensor(66130848., grad_fn=<AddBackward0>)\n",
      "tensor(65504024., grad_fn=<AddBackward0>)\n",
      "tensor(64891196., grad_fn=<AddBackward0>)\n",
      "tensor(64292108., grad_fn=<AddBackward0>)\n",
      "tensor(63706416., grad_fn=<AddBackward0>)\n",
      "tensor(63133812., grad_fn=<AddBackward0>)\n",
      "tensor(62573648., grad_fn=<AddBackward0>)\n",
      "tensor(62025652., grad_fn=<AddBackward0>)\n",
      "tensor(61489588., grad_fn=<AddBackward0>)\n",
      "tensor(60965124., grad_fn=<AddBackward0>)\n",
      "tensor(60451640., grad_fn=<AddBackward0>)\n",
      "tensor(59948924., grad_fn=<AddBackward0>)\n",
      "tensor(59456780., grad_fn=<AddBackward0>)\n",
      "tensor(58974804., grad_fn=<AddBackward0>)\n",
      "tensor(58502708., grad_fn=<AddBackward0>)\n",
      "tensor(58040156., grad_fn=<AddBackward0>)\n",
      "tensor(57586944., grad_fn=<AddBackward0>)\n",
      "tensor(57142864., grad_fn=<AddBackward0>)\n",
      "tensor(56707508., grad_fn=<AddBackward0>)\n",
      "tensor(56280676., grad_fn=<AddBackward0>)\n",
      "tensor(55862344., grad_fn=<AddBackward0>)\n",
      "tensor(55452052., grad_fn=<AddBackward0>)\n",
      "tensor(55049652., grad_fn=<AddBackward0>)\n",
      "tensor(54655004., grad_fn=<AddBackward0>)\n",
      "tensor(54267864., grad_fn=<AddBackward0>)\n",
      "tensor(53888036., grad_fn=<AddBackward0>)\n",
      "tensor(53515140., grad_fn=<AddBackward0>)\n",
      "tensor(53149164., grad_fn=<AddBackward0>)\n",
      "tensor(52789852., grad_fn=<AddBackward0>)\n",
      "tensor(52436992., grad_fn=<AddBackward0>)\n",
      "tensor(52090420., grad_fn=<AddBackward0>)\n",
      "tensor(51749996., grad_fn=<AddBackward0>)\n",
      "tensor(51415520., grad_fn=<AddBackward0>)\n",
      "tensor(51086840., grad_fn=<AddBackward0>)\n",
      "tensor(50763812., grad_fn=<AddBackward0>)\n",
      "tensor(50446284., grad_fn=<AddBackward0>)\n",
      "tensor(50134012., grad_fn=<AddBackward0>)\n",
      "tensor(49826884., grad_fn=<AddBackward0>)\n",
      "tensor(49524856., grad_fn=<AddBackward0>)\n",
      "tensor(49227764., grad_fn=<AddBackward0>)\n",
      "tensor(48935376., grad_fn=<AddBackward0>)\n",
      "tensor(48647548., grad_fn=<AddBackward0>)\n",
      "tensor(48364288., grad_fn=<AddBackward0>)\n",
      "tensor(48085384., grad_fn=<AddBackward0>)\n",
      "tensor(47810832., grad_fn=<AddBackward0>)\n",
      "tensor(47540360., grad_fn=<AddBackward0>)\n",
      "tensor(47274076., grad_fn=<AddBackward0>)\n",
      "tensor(47011688., grad_fn=<AddBackward0>)\n",
      "tensor(46753228., grad_fn=<AddBackward0>)\n",
      "tensor(46498464., grad_fn=<AddBackward0>)\n",
      "tensor(46247348., grad_fn=<AddBackward0>)\n",
      "tensor(45999796., grad_fn=<AddBackward0>)\n",
      "tensor(45755832., grad_fn=<AddBackward0>)\n",
      "tensor(45515308., grad_fn=<AddBackward0>)\n",
      "tensor(45278068., grad_fn=<AddBackward0>)\n",
      "tensor(45044160., grad_fn=<AddBackward0>)\n",
      "tensor(44813324., grad_fn=<AddBackward0>)\n",
      "tensor(44585608., grad_fn=<AddBackward0>)\n",
      "tensor(44360924., grad_fn=<AddBackward0>)\n",
      "tensor(44139212., grad_fn=<AddBackward0>)\n",
      "tensor(43920380., grad_fn=<AddBackward0>)\n",
      "tensor(43704268., grad_fn=<AddBackward0>)\n",
      "tensor(43490920., grad_fn=<AddBackward0>)\n",
      "tensor(43280184., grad_fn=<AddBackward0>)\n",
      "tensor(43071992., grad_fn=<AddBackward0>)\n",
      "tensor(42866432., grad_fn=<AddBackward0>)\n",
      "tensor(42663456., grad_fn=<AddBackward0>)\n",
      "tensor(42462960., grad_fn=<AddBackward0>)\n",
      "tensor(42264892., grad_fn=<AddBackward0>)\n",
      "tensor(42069172., grad_fn=<AddBackward0>)\n",
      "tensor(41875676., grad_fn=<AddBackward0>)\n",
      "tensor(41684484., grad_fn=<AddBackward0>)\n",
      "tensor(41495480., grad_fn=<AddBackward0>)\n",
      "tensor(41308676., grad_fn=<AddBackward0>)\n",
      "tensor(41123972., grad_fn=<AddBackward0>)\n",
      "tensor(40941276., grad_fn=<AddBackward0>)\n",
      "tensor(40760700., grad_fn=<AddBackward0>)\n",
      "tensor(40582036., grad_fn=<AddBackward0>)\n",
      "tensor(40405472., grad_fn=<AddBackward0>)\n",
      "tensor(40230692., grad_fn=<AddBackward0>)\n",
      "tensor(40057752., grad_fn=<AddBackward0>)\n",
      "tensor(39886680., grad_fn=<AddBackward0>)\n",
      "tensor(39717400., grad_fn=<AddBackward0>)\n",
      "tensor(39549788., grad_fn=<AddBackward0>)\n",
      "tensor(39383920., grad_fn=<AddBackward0>)\n",
      "tensor(39219732., grad_fn=<AddBackward0>)\n",
      "tensor(39057152., grad_fn=<AddBackward0>)\n",
      "tensor(38896260., grad_fn=<AddBackward0>)\n",
      "tensor(38736892., grad_fn=<AddBackward0>)\n",
      "tensor(38579048., grad_fn=<AddBackward0>)\n",
      "tensor(38422776., grad_fn=<AddBackward0>)\n",
      "tensor(38267976., grad_fn=<AddBackward0>)\n",
      "tensor(38114572., grad_fn=<AddBackward0>)\n",
      "tensor(37962624., grad_fn=<AddBackward0>)\n",
      "tensor(37812036., grad_fn=<AddBackward0>)\n",
      "tensor(37662856., grad_fn=<AddBackward0>)\n",
      "tensor(37515052., grad_fn=<AddBackward0>)\n",
      "tensor(37368544., grad_fn=<AddBackward0>)\n",
      "tensor(37223416., grad_fn=<AddBackward0>)\n",
      "tensor(37079564., grad_fn=<AddBackward0>)\n",
      "tensor(36936948., grad_fn=<AddBackward0>)\n",
      "tensor(36795632., grad_fn=<AddBackward0>)\n",
      "tensor(36655476., grad_fn=<AddBackward0>)\n",
      "tensor(36516576., grad_fn=<AddBackward0>)\n",
      "tensor(36378844., grad_fn=<AddBackward0>)\n",
      "tensor(36242288., grad_fn=<AddBackward0>)\n",
      "tensor(36106936., grad_fn=<AddBackward0>)\n",
      "tensor(35972700., grad_fn=<AddBackward0>)\n",
      "tensor(35839620., grad_fn=<AddBackward0>)\n",
      "tensor(35707580., grad_fn=<AddBackward0>)\n",
      "tensor(35576640., grad_fn=<AddBackward0>)\n",
      "tensor(35446764., grad_fn=<AddBackward0>)\n",
      "tensor(35317920., grad_fn=<AddBackward0>)\n",
      "tensor(35190108., grad_fn=<AddBackward0>)\n",
      "tensor(35063276., grad_fn=<AddBackward0>)\n",
      "tensor(34937460., grad_fn=<AddBackward0>)\n",
      "tensor(34812616., grad_fn=<AddBackward0>)\n",
      "tensor(34688768., grad_fn=<AddBackward0>)\n",
      "tensor(34565836., grad_fn=<AddBackward0>)\n",
      "tensor(34443908., grad_fn=<AddBackward0>)\n",
      "tensor(34322884., grad_fn=<AddBackward0>)\n",
      "tensor(34202768., grad_fn=<AddBackward0>)\n",
      "tensor(34083532., grad_fn=<AddBackward0>)\n",
      "tensor(33965168., grad_fn=<AddBackward0>)\n",
      "tensor(33847676., grad_fn=<AddBackward0>)\n",
      "tensor(33731068., grad_fn=<AddBackward0>)\n",
      "tensor(33615332., grad_fn=<AddBackward0>)\n",
      "tensor(33500452., grad_fn=<AddBackward0>)\n",
      "tensor(33386438., grad_fn=<AddBackward0>)\n",
      "tensor(33273254., grad_fn=<AddBackward0>)\n",
      "tensor(33160864., grad_fn=<AddBackward0>)\n",
      "tensor(33049306., grad_fn=<AddBackward0>)\n",
      "tensor(32938550., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(32828518., grad_fn=<AddBackward0>)\n",
      "tensor(32719256., grad_fn=<AddBackward0>)\n",
      "tensor(32610712., grad_fn=<AddBackward0>)\n",
      "tensor(32502948., grad_fn=<AddBackward0>)\n",
      "tensor(32395944., grad_fn=<AddBackward0>)\n",
      "tensor(32289662., grad_fn=<AddBackward0>)\n",
      "tensor(32184138., grad_fn=<AddBackward0>)\n",
      "tensor(32079318., grad_fn=<AddBackward0>)\n",
      "tensor(31975182., grad_fn=<AddBackward0>)\n",
      "tensor(31871768., grad_fn=<AddBackward0>)\n",
      "tensor(31769038., grad_fn=<AddBackward0>)\n",
      "tensor(31666976., grad_fn=<AddBackward0>)\n",
      "tensor(31565596., grad_fn=<AddBackward0>)\n",
      "tensor(31464888., grad_fn=<AddBackward0>)\n",
      "tensor(31364798., grad_fn=<AddBackward0>)\n",
      "tensor(31265356., grad_fn=<AddBackward0>)\n",
      "tensor(31166570., grad_fn=<AddBackward0>)\n",
      "tensor(31068354., grad_fn=<AddBackward0>)\n",
      "tensor(30970794., grad_fn=<AddBackward0>)\n",
      "tensor(30873870., grad_fn=<AddBackward0>)\n",
      "tensor(30777514., grad_fn=<AddBackward0>)\n",
      "tensor(30681786., grad_fn=<AddBackward0>)\n",
      "tensor(30586692., grad_fn=<AddBackward0>)\n",
      "tensor(30492172., grad_fn=<AddBackward0>)\n",
      "tensor(30398198., grad_fn=<AddBackward0>)\n",
      "tensor(30304788., grad_fn=<AddBackward0>)\n",
      "tensor(30211926., grad_fn=<AddBackward0>)\n",
      "tensor(30119654., grad_fn=<AddBackward0>)\n",
      "tensor(30027936., grad_fn=<AddBackward0>)\n",
      "tensor(29936798., grad_fn=<AddBackward0>)\n",
      "tensor(29846166., grad_fn=<AddBackward0>)\n",
      "tensor(29756078., grad_fn=<AddBackward0>)\n",
      "tensor(29666544., grad_fn=<AddBackward0>)\n",
      "tensor(29577532., grad_fn=<AddBackward0>)\n",
      "tensor(29489052., grad_fn=<AddBackward0>)\n",
      "tensor(29401106., grad_fn=<AddBackward0>)\n",
      "tensor(29313642., grad_fn=<AddBackward0>)\n",
      "tensor(29226670., grad_fn=<AddBackward0>)\n",
      "tensor(29140214., grad_fn=<AddBackward0>)\n",
      "tensor(29054284., grad_fn=<AddBackward0>)\n",
      "tensor(28968828., grad_fn=<AddBackward0>)\n",
      "tensor(28883822., grad_fn=<AddBackward0>)\n",
      "tensor(28799326., grad_fn=<AddBackward0>)\n",
      "tensor(28715274., grad_fn=<AddBackward0>)\n",
      "tensor(28631654., grad_fn=<AddBackward0>)\n",
      "tensor(28548506., grad_fn=<AddBackward0>)\n",
      "tensor(28465830., grad_fn=<AddBackward0>)\n",
      "tensor(28383644., grad_fn=<AddBackward0>)\n",
      "tensor(28301856., grad_fn=<AddBackward0>)\n",
      "tensor(28220524., grad_fn=<AddBackward0>)\n",
      "tensor(28139616., grad_fn=<AddBackward0>)\n",
      "tensor(28059116., grad_fn=<AddBackward0>)\n",
      "tensor(27979060., grad_fn=<AddBackward0>)\n",
      "tensor(27899454., grad_fn=<AddBackward0>)\n",
      "tensor(27820230., grad_fn=<AddBackward0>)\n",
      "tensor(27741450., grad_fn=<AddBackward0>)\n",
      "tensor(27663124., grad_fn=<AddBackward0>)\n",
      "tensor(27585204., grad_fn=<AddBackward0>)\n",
      "tensor(27507730., grad_fn=<AddBackward0>)\n",
      "tensor(27430604., grad_fn=<AddBackward0>)\n",
      "tensor(27353916., grad_fn=<AddBackward0>)\n",
      "tensor(27277618., grad_fn=<AddBackward0>)\n",
      "tensor(27201750., grad_fn=<AddBackward0>)\n",
      "tensor(27126234., grad_fn=<AddBackward0>)\n",
      "tensor(27051102., grad_fn=<AddBackward0>)\n",
      "tensor(26976406., grad_fn=<AddBackward0>)\n",
      "tensor(26902080., grad_fn=<AddBackward0>)\n",
      "tensor(26828118., grad_fn=<AddBackward0>)\n",
      "tensor(26754510., grad_fn=<AddBackward0>)\n",
      "tensor(26681286., grad_fn=<AddBackward0>)\n",
      "tensor(26608424., grad_fn=<AddBackward0>)\n",
      "tensor(26535900., grad_fn=<AddBackward0>)\n",
      "tensor(26463750., grad_fn=<AddBackward0>)\n",
      "tensor(26391964., grad_fn=<AddBackward0>)\n",
      "tensor(26320518., grad_fn=<AddBackward0>)\n",
      "tensor(26249454., grad_fn=<AddBackward0>)\n",
      "tensor(26178740., grad_fn=<AddBackward0>)\n",
      "tensor(26108356., grad_fn=<AddBackward0>)\n",
      "tensor(26038294., grad_fn=<AddBackward0>)\n",
      "tensor(25968600., grad_fn=<AddBackward0>)\n",
      "tensor(25899212., grad_fn=<AddBackward0>)\n",
      "tensor(25830170., grad_fn=<AddBackward0>)\n",
      "tensor(25761464., grad_fn=<AddBackward0>)\n",
      "tensor(25693058., grad_fn=<AddBackward0>)\n",
      "tensor(25625010., grad_fn=<AddBackward0>)\n",
      "tensor(25557272., grad_fn=<AddBackward0>)\n",
      "tensor(25489864., grad_fn=<AddBackward0>)\n",
      "tensor(25422752., grad_fn=<AddBackward0>)\n",
      "tensor(25355990., grad_fn=<AddBackward0>)\n",
      "tensor(25289518., grad_fn=<AddBackward0>)\n",
      "tensor(25223368., grad_fn=<AddBackward0>)\n",
      "tensor(25157506., grad_fn=<AddBackward0>)\n",
      "tensor(25091964., grad_fn=<AddBackward0>)\n",
      "tensor(25026752., grad_fn=<AddBackward0>)\n",
      "tensor(24961806., grad_fn=<AddBackward0>)\n",
      "tensor(24897192., grad_fn=<AddBackward0>)\n",
      "tensor(24832842., grad_fn=<AddBackward0>)\n",
      "tensor(24768792., grad_fn=<AddBackward0>)\n",
      "tensor(24705046., grad_fn=<AddBackward0>)\n",
      "tensor(24641574., grad_fn=<AddBackward0>)\n",
      "tensor(24578400., grad_fn=<AddBackward0>)\n",
      "tensor(24515468., grad_fn=<AddBackward0>)\n",
      "tensor(24452860., grad_fn=<AddBackward0>)\n",
      "tensor(24390502., grad_fn=<AddBackward0>)\n",
      "tensor(24328436., grad_fn=<AddBackward0>)\n",
      "tensor(24266666., grad_fn=<AddBackward0>)\n",
      "tensor(24205118., grad_fn=<AddBackward0>)\n",
      "tensor(24143872., grad_fn=<AddBackward0>)\n",
      "tensor(24082918., grad_fn=<AddBackward0>)\n",
      "tensor(24022218., grad_fn=<AddBackward0>)\n",
      "tensor(23961772., grad_fn=<AddBackward0>)\n",
      "tensor(23901582., grad_fn=<AddBackward0>)\n",
      "tensor(23841688., grad_fn=<AddBackward0>)\n",
      "tensor(23782038., grad_fn=<AddBackward0>)\n",
      "tensor(23722628., grad_fn=<AddBackward0>)\n",
      "tensor(23663488., grad_fn=<AddBackward0>)\n",
      "tensor(23604572., grad_fn=<AddBackward0>)\n",
      "tensor(23545942., grad_fn=<AddBackward0>)\n",
      "tensor(23487534., grad_fn=<AddBackward0>)\n",
      "tensor(23429380., grad_fn=<AddBackward0>)\n",
      "tensor(23371452., grad_fn=<AddBackward0>)\n",
      "tensor(23313818., grad_fn=<AddBackward0>)\n",
      "tensor(23256394., grad_fn=<AddBackward0>)\n",
      "tensor(23199234., grad_fn=<AddBackward0>)\n",
      "tensor(23142294., grad_fn=<AddBackward0>)\n",
      "tensor(23085590., grad_fn=<AddBackward0>)\n",
      "tensor(23029124., grad_fn=<AddBackward0>)\n",
      "tensor(22972870., grad_fn=<AddBackward0>)\n",
      "tensor(22916866., grad_fn=<AddBackward0>)\n",
      "tensor(22861064., grad_fn=<AddBackward0>)\n",
      "tensor(22805506., grad_fn=<AddBackward0>)\n",
      "tensor(22750204., grad_fn=<AddBackward0>)\n",
      "tensor(22695114., grad_fn=<AddBackward0>)\n",
      "tensor(22640250., grad_fn=<AddBackward0>)\n",
      "tensor(22585586., grad_fn=<AddBackward0>)\n",
      "tensor(22531144., grad_fn=<AddBackward0>)\n",
      "tensor(22476906., grad_fn=<AddBackward0>)\n",
      "tensor(22422920., grad_fn=<AddBackward0>)\n",
      "tensor(22369114., grad_fn=<AddBackward0>)\n",
      "tensor(22315518., grad_fn=<AddBackward0>)\n",
      "tensor(22262134., grad_fn=<AddBackward0>)\n",
      "tensor(22208952., grad_fn=<AddBackward0>)\n",
      "tensor(22155966., grad_fn=<AddBackward0>)\n",
      "tensor(22103208., grad_fn=<AddBackward0>)\n",
      "tensor(22050640., grad_fn=<AddBackward0>)\n",
      "tensor(21998284., grad_fn=<AddBackward0>)\n",
      "tensor(21946134., grad_fn=<AddBackward0>)\n",
      "tensor(21894198., grad_fn=<AddBackward0>)\n",
      "tensor(21842440., grad_fn=<AddBackward0>)\n",
      "tensor(21790892., grad_fn=<AddBackward0>)\n",
      "tensor(21739544., grad_fn=<AddBackward0>)\n",
      "tensor(21688412., grad_fn=<AddBackward0>)\n",
      "tensor(21637450., grad_fn=<AddBackward0>)\n",
      "tensor(21586700., grad_fn=<AddBackward0>)\n",
      "tensor(21536130., grad_fn=<AddBackward0>)\n",
      "tensor(21485746., grad_fn=<AddBackward0>)\n",
      "tensor(21435550., grad_fn=<AddBackward0>)\n",
      "tensor(21385530., grad_fn=<AddBackward0>)\n",
      "tensor(21335716., grad_fn=<AddBackward0>)\n",
      "tensor(21286100., grad_fn=<AddBackward0>)\n",
      "tensor(21236660., grad_fn=<AddBackward0>)\n",
      "tensor(21187434., grad_fn=<AddBackward0>)\n",
      "tensor(21138336., grad_fn=<AddBackward0>)\n",
      "tensor(21089454., grad_fn=<AddBackward0>)\n",
      "tensor(21040736., grad_fn=<AddBackward0>)\n",
      "tensor(20992218., grad_fn=<AddBackward0>)\n",
      "tensor(20943864., grad_fn=<AddBackward0>)\n",
      "tensor(20895712., grad_fn=<AddBackward0>)\n",
      "tensor(20847722., grad_fn=<AddBackward0>)\n",
      "tensor(20799912., grad_fn=<AddBackward0>)\n",
      "tensor(20752264., grad_fn=<AddBackward0>)\n",
      "tensor(20704786., grad_fn=<AddBackward0>)\n",
      "tensor(20657484., grad_fn=<AddBackward0>)\n",
      "tensor(20610384., grad_fn=<AddBackward0>)\n",
      "tensor(20563432., grad_fn=<AddBackward0>)\n",
      "tensor(20516664., grad_fn=<AddBackward0>)\n",
      "tensor(20470054., grad_fn=<AddBackward0>)\n",
      "tensor(20423624., grad_fn=<AddBackward0>)\n",
      "tensor(20377340., grad_fn=<AddBackward0>)\n",
      "tensor(20331230., grad_fn=<AddBackward0>)\n",
      "tensor(20285292., grad_fn=<AddBackward0>)\n",
      "tensor(20239532., grad_fn=<AddBackward0>)\n",
      "tensor(20193944., grad_fn=<AddBackward0>)\n",
      "tensor(20148460., grad_fn=<AddBackward0>)\n",
      "tensor(20103196., grad_fn=<AddBackward0>)\n",
      "tensor(20058092., grad_fn=<AddBackward0>)\n",
      "tensor(20013100., grad_fn=<AddBackward0>)\n",
      "tensor(19968298., grad_fn=<AddBackward0>)\n",
      "tensor(19923648., grad_fn=<AddBackward0>)\n",
      "tensor(19879170., grad_fn=<AddBackward0>)\n",
      "tensor(19834838., grad_fn=<AddBackward0>)\n",
      "tensor(19790658., grad_fn=<AddBackward0>)\n",
      "tensor(19746656., grad_fn=<AddBackward0>)\n",
      "tensor(19702794., grad_fn=<AddBackward0>)\n",
      "tensor(19659072., grad_fn=<AddBackward0>)\n",
      "tensor(19615526., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(19572130., grad_fn=<AddBackward0>)\n",
      "tensor(19528898., grad_fn=<AddBackward0>)\n",
      "tensor(19485798., grad_fn=<AddBackward0>)\n",
      "tensor(19442852., grad_fn=<AddBackward0>)\n",
      "tensor(19400044., grad_fn=<AddBackward0>)\n",
      "tensor(19357410., grad_fn=<AddBackward0>)\n",
      "tensor(19314908., grad_fn=<AddBackward0>)\n",
      "tensor(19272550., grad_fn=<AddBackward0>)\n",
      "tensor(19230352., grad_fn=<AddBackward0>)\n",
      "tensor(19188294., grad_fn=<AddBackward0>)\n",
      "tensor(19146358., grad_fn=<AddBackward0>)\n",
      "tensor(19104570., grad_fn=<AddBackward0>)\n",
      "tensor(19062922., grad_fn=<AddBackward0>)\n",
      "tensor(19021398., grad_fn=<AddBackward0>)\n",
      "tensor(18980028., grad_fn=<AddBackward0>)\n",
      "tensor(18938822., grad_fn=<AddBackward0>)\n",
      "tensor(18897748., grad_fn=<AddBackward0>)\n",
      "tensor(18856780., grad_fn=<AddBackward0>)\n",
      "tensor(18815954., grad_fn=<AddBackward0>)\n",
      "tensor(18775288., grad_fn=<AddBackward0>)\n",
      "tensor(18734726., grad_fn=<AddBackward0>)\n",
      "tensor(18694304., grad_fn=<AddBackward0>)\n",
      "tensor(18654024., grad_fn=<AddBackward0>)\n",
      "tensor(18613856., grad_fn=<AddBackward0>)\n",
      "tensor(18573834., grad_fn=<AddBackward0>)\n",
      "tensor(18533924., grad_fn=<AddBackward0>)\n",
      "tensor(18494158., grad_fn=<AddBackward0>)\n",
      "tensor(18454510., grad_fn=<AddBackward0>)\n",
      "tensor(18415006., grad_fn=<AddBackward0>)\n",
      "tensor(18375620., grad_fn=<AddBackward0>)\n",
      "tensor(18336366., grad_fn=<AddBackward0>)\n",
      "tensor(18297230., grad_fn=<AddBackward0>)\n",
      "tensor(18258230., grad_fn=<AddBackward0>)\n",
      "tensor(18219362., grad_fn=<AddBackward0>)\n",
      "tensor(18180632., grad_fn=<AddBackward0>)\n",
      "tensor(18142018., grad_fn=<AddBackward0>)\n",
      "tensor(18103514., grad_fn=<AddBackward0>)\n",
      "tensor(18065134., grad_fn=<AddBackward0>)\n",
      "tensor(18026902., grad_fn=<AddBackward0>)\n",
      "tensor(17988792., grad_fn=<AddBackward0>)\n",
      "tensor(17950798., grad_fn=<AddBackward0>)\n",
      "tensor(17912926., grad_fn=<AddBackward0>)\n",
      "tensor(17875188., grad_fn=<AddBackward0>)\n",
      "tensor(17837562., grad_fn=<AddBackward0>)\n",
      "tensor(17800054., grad_fn=<AddBackward0>)\n",
      "tensor(17762686., grad_fn=<AddBackward0>)\n",
      "tensor(17725420., grad_fn=<AddBackward0>)\n",
      "tensor(17688284., grad_fn=<AddBackward0>)\n",
      "tensor(17651248., grad_fn=<AddBackward0>)\n",
      "tensor(17614332., grad_fn=<AddBackward0>)\n",
      "tensor(17577526., grad_fn=<AddBackward0>)\n",
      "tensor(17540850., grad_fn=<AddBackward0>)\n",
      "tensor(17504280., grad_fn=<AddBackward0>)\n",
      "tensor(17467832., grad_fn=<AddBackward0>)\n",
      "tensor(17431502., grad_fn=<AddBackward0>)\n",
      "tensor(17395274., grad_fn=<AddBackward0>)\n",
      "tensor(17359164., grad_fn=<AddBackward0>)\n",
      "tensor(17323164., grad_fn=<AddBackward0>)\n",
      "tensor(17287280., grad_fn=<AddBackward0>)\n",
      "tensor(17251482., grad_fn=<AddBackward0>)\n",
      "tensor(17215830., grad_fn=<AddBackward0>)\n",
      "tensor(17180268., grad_fn=<AddBackward0>)\n",
      "tensor(17144832., grad_fn=<AddBackward0>)\n",
      "tensor(17109500., grad_fn=<AddBackward0>)\n",
      "tensor(17074278., grad_fn=<AddBackward0>)\n",
      "tensor(17039154., grad_fn=<AddBackward0>)\n",
      "tensor(17004140., grad_fn=<AddBackward0>)\n",
      "tensor(16969242., grad_fn=<AddBackward0>)\n",
      "tensor(16934440., grad_fn=<AddBackward0>)\n",
      "tensor(16899746., grad_fn=<AddBackward0>)\n",
      "tensor(16865148., grad_fn=<AddBackward0>)\n",
      "tensor(16830664., grad_fn=<AddBackward0>)\n",
      "tensor(16796274., grad_fn=<AddBackward0>)\n",
      "tensor(16761998., grad_fn=<AddBackward0>)\n",
      "tensor(16727808., grad_fn=<AddBackward0>)\n",
      "tensor(16693705., grad_fn=<AddBackward0>)\n",
      "tensor(16659719., grad_fn=<AddBackward0>)\n",
      "tensor(16625841., grad_fn=<AddBackward0>)\n",
      "tensor(16592058., grad_fn=<AddBackward0>)\n",
      "tensor(16558387., grad_fn=<AddBackward0>)\n",
      "tensor(16524792., grad_fn=<AddBackward0>)\n",
      "tensor(16491327., grad_fn=<AddBackward0>)\n",
      "tensor(16457936., grad_fn=<AddBackward0>)\n",
      "tensor(16424651., grad_fn=<AddBackward0>)\n",
      "tensor(16391462., grad_fn=<AddBackward0>)\n",
      "tensor(16358378., grad_fn=<AddBackward0>)\n",
      "tensor(16325367., grad_fn=<AddBackward0>)\n",
      "tensor(16292472., grad_fn=<AddBackward0>)\n",
      "tensor(16259675., grad_fn=<AddBackward0>)\n",
      "tensor(16226951., grad_fn=<AddBackward0>)\n",
      "tensor(16194347., grad_fn=<AddBackward0>)\n",
      "tensor(16161838., grad_fn=<AddBackward0>)\n",
      "tensor(16129421., grad_fn=<AddBackward0>)\n",
      "tensor(16097106., grad_fn=<AddBackward0>)\n",
      "tensor(16064872., grad_fn=<AddBackward0>)\n",
      "tensor(16032745., grad_fn=<AddBackward0>)\n",
      "tensor(16000709., grad_fn=<AddBackward0>)\n",
      "tensor(15968771., grad_fn=<AddBackward0>)\n",
      "tensor(15936927., grad_fn=<AddBackward0>)\n",
      "tensor(15905156., grad_fn=<AddBackward0>)\n",
      "tensor(15873498., grad_fn=<AddBackward0>)\n",
      "tensor(15841921., grad_fn=<AddBackward0>)\n",
      "tensor(15810438., grad_fn=<AddBackward0>)\n",
      "tensor(15779064., grad_fn=<AddBackward0>)\n",
      "tensor(15747721., grad_fn=<AddBackward0>)\n",
      "tensor(15716512., grad_fn=<AddBackward0>)\n",
      "tensor(15685386., grad_fn=<AddBackward0>)\n",
      "tensor(15654356., grad_fn=<AddBackward0>)\n",
      "tensor(15623422., grad_fn=<AddBackward0>)\n",
      "tensor(15592560., grad_fn=<AddBackward0>)\n",
      "tensor(15561781., grad_fn=<AddBackward0>)\n",
      "tensor(15531083., grad_fn=<AddBackward0>)\n",
      "tensor(15500479., grad_fn=<AddBackward0>)\n",
      "tensor(15469982., grad_fn=<AddBackward0>)\n",
      "tensor(15439541., grad_fn=<AddBackward0>)\n",
      "tensor(15409214., grad_fn=<AddBackward0>)\n",
      "tensor(15378969., grad_fn=<AddBackward0>)\n",
      "tensor(15348796., grad_fn=<AddBackward0>)\n",
      "tensor(15318723., grad_fn=<AddBackward0>)\n",
      "tensor(15288730., grad_fn=<AddBackward0>)\n",
      "tensor(15258813., grad_fn=<AddBackward0>)\n",
      "tensor(15228992., grad_fn=<AddBackward0>)\n",
      "tensor(15199231., grad_fn=<AddBackward0>)\n",
      "tensor(15169554., grad_fn=<AddBackward0>)\n",
      "tensor(15139966., grad_fn=<AddBackward0>)\n",
      "tensor(15110473., grad_fn=<AddBackward0>)\n",
      "tensor(15081047., grad_fn=<AddBackward0>)\n",
      "tensor(15051719., grad_fn=<AddBackward0>)\n",
      "tensor(15022462., grad_fn=<AddBackward0>)\n",
      "tensor(14993293., grad_fn=<AddBackward0>)\n",
      "tensor(14964194., grad_fn=<AddBackward0>)\n",
      "tensor(14935173., grad_fn=<AddBackward0>)\n",
      "tensor(14906257., grad_fn=<AddBackward0>)\n",
      "tensor(14877407., grad_fn=<AddBackward0>)\n",
      "tensor(14848631., grad_fn=<AddBackward0>)\n",
      "tensor(14819948., grad_fn=<AddBackward0>)\n",
      "tensor(14791326., grad_fn=<AddBackward0>)\n",
      "tensor(14762789., grad_fn=<AddBackward0>)\n",
      "tensor(14734335., grad_fn=<AddBackward0>)\n",
      "tensor(14705977., grad_fn=<AddBackward0>)\n",
      "tensor(14677660., grad_fn=<AddBackward0>)\n",
      "tensor(14649418., grad_fn=<AddBackward0>)\n",
      "tensor(14621288., grad_fn=<AddBackward0>)\n",
      "tensor(14593212., grad_fn=<AddBackward0>)\n",
      "tensor(14565200., grad_fn=<AddBackward0>)\n",
      "tensor(14537296., grad_fn=<AddBackward0>)\n",
      "tensor(14509461., grad_fn=<AddBackward0>)\n",
      "tensor(14481678., grad_fn=<AddBackward0>)\n",
      "tensor(14454002., grad_fn=<AddBackward0>)\n",
      "tensor(14426381., grad_fn=<AddBackward0>)\n",
      "tensor(14398838., grad_fn=<AddBackward0>)\n",
      "tensor(14371377., grad_fn=<AddBackward0>)\n",
      "tensor(14344008., grad_fn=<AddBackward0>)\n",
      "tensor(14316706., grad_fn=<AddBackward0>)\n",
      "tensor(14289457., grad_fn=<AddBackward0>)\n",
      "tensor(14262301., grad_fn=<AddBackward0>)\n",
      "tensor(14235223., grad_fn=<AddBackward0>)\n",
      "tensor(14208210., grad_fn=<AddBackward0>)\n",
      "tensor(14181276., grad_fn=<AddBackward0>)\n",
      "tensor(14154420., grad_fn=<AddBackward0>)\n",
      "tensor(14127617., grad_fn=<AddBackward0>)\n",
      "tensor(14100879., grad_fn=<AddBackward0>)\n",
      "tensor(14074236., grad_fn=<AddBackward0>)\n",
      "tensor(14047649., grad_fn=<AddBackward0>)\n",
      "tensor(14021123., grad_fn=<AddBackward0>)\n",
      "tensor(13994682., grad_fn=<AddBackward0>)\n",
      "tensor(13968317., grad_fn=<AddBackward0>)\n",
      "tensor(13942002., grad_fn=<AddBackward0>)\n",
      "tensor(13915775., grad_fn=<AddBackward0>)\n",
      "tensor(13889612., grad_fn=<AddBackward0>)\n",
      "tensor(13863497., grad_fn=<AddBackward0>)\n",
      "tensor(13837455., grad_fn=<AddBackward0>)\n",
      "tensor(13811492., grad_fn=<AddBackward0>)\n",
      "tensor(13785603., grad_fn=<AddBackward0>)\n",
      "tensor(13759757., grad_fn=<AddBackward0>)\n",
      "tensor(13733998., grad_fn=<AddBackward0>)\n",
      "tensor(13708291., grad_fn=<AddBackward0>)\n",
      "tensor(13682651., grad_fn=<AddBackward0>)\n",
      "tensor(13657090., grad_fn=<AddBackward0>)\n",
      "tensor(13631599., grad_fn=<AddBackward0>)\n",
      "tensor(13606174., grad_fn=<AddBackward0>)\n",
      "tensor(13580812., grad_fn=<AddBackward0>)\n",
      "tensor(13555520., grad_fn=<AddBackward0>)\n",
      "tensor(13530289., grad_fn=<AddBackward0>)\n",
      "tensor(13505142., grad_fn=<AddBackward0>)\n",
      "tensor(13480031., grad_fn=<AddBackward0>)\n",
      "tensor(13455000., grad_fn=<AddBackward0>)\n",
      "tensor(13430030., grad_fn=<AddBackward0>)\n",
      "tensor(13405144., grad_fn=<AddBackward0>)\n",
      "tensor(13380319., grad_fn=<AddBackward0>)\n",
      "tensor(13355550., grad_fn=<AddBackward0>)\n",
      "tensor(13330871., grad_fn=<AddBackward0>)\n",
      "tensor(13306236., grad_fn=<AddBackward0>)\n",
      "tensor(13281654., grad_fn=<AddBackward0>)\n",
      "tensor(13257165., grad_fn=<AddBackward0>)\n",
      "tensor(13232714., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(13208348., grad_fn=<AddBackward0>)\n",
      "tensor(13184039., grad_fn=<AddBackward0>)\n",
      "tensor(13159802., grad_fn=<AddBackward0>)\n",
      "tensor(13135611., grad_fn=<AddBackward0>)\n",
      "tensor(13111494., grad_fn=<AddBackward0>)\n",
      "tensor(13087431., grad_fn=<AddBackward0>)\n",
      "tensor(13063441., grad_fn=<AddBackward0>)\n",
      "tensor(13039505., grad_fn=<AddBackward0>)\n",
      "tensor(13015630., grad_fn=<AddBackward0>)\n",
      "tensor(12991810., grad_fn=<AddBackward0>)\n",
      "tensor(12968064., grad_fn=<AddBackward0>)\n",
      "tensor(12944374., grad_fn=<AddBackward0>)\n",
      "tensor(12920755., grad_fn=<AddBackward0>)\n",
      "tensor(12897195., grad_fn=<AddBackward0>)\n",
      "tensor(12873660., grad_fn=<AddBackward0>)\n",
      "tensor(12850221., grad_fn=<AddBackward0>)\n",
      "tensor(12826835., grad_fn=<AddBackward0>)\n",
      "tensor(12803495., grad_fn=<AddBackward0>)\n",
      "tensor(12780233., grad_fn=<AddBackward0>)\n",
      "tensor(12757023., grad_fn=<AddBackward0>)\n",
      "tensor(12733868., grad_fn=<AddBackward0>)\n",
      "tensor(12710771., grad_fn=<AddBackward0>)\n",
      "tensor(12687742., grad_fn=<AddBackward0>)\n",
      "tensor(12664777., grad_fn=<AddBackward0>)\n",
      "tensor(12641857., grad_fn=<AddBackward0>)\n",
      "tensor(12619000., grad_fn=<AddBackward0>)\n",
      "tensor(12596197., grad_fn=<AddBackward0>)\n",
      "tensor(12573465., grad_fn=<AddBackward0>)\n",
      "tensor(12550780., grad_fn=<AddBackward0>)\n",
      "tensor(12528148., grad_fn=<AddBackward0>)\n",
      "tensor(12505582., grad_fn=<AddBackward0>)\n",
      "tensor(12483051., grad_fn=<AddBackward0>)\n",
      "tensor(12460593., grad_fn=<AddBackward0>)\n",
      "tensor(12438193., grad_fn=<AddBackward0>)\n",
      "tensor(12415838., grad_fn=<AddBackward0>)\n",
      "tensor(12393558., grad_fn=<AddBackward0>)\n",
      "tensor(12371310., grad_fn=<AddBackward0>)\n",
      "tensor(12349135., grad_fn=<AddBackward0>)\n",
      "tensor(12327024., grad_fn=<AddBackward0>)\n",
      "tensor(12304956., grad_fn=<AddBackward0>)\n",
      "tensor(12282935., grad_fn=<AddBackward0>)\n",
      "tensor(12260973., grad_fn=<AddBackward0>)\n",
      "tensor(12239075., grad_fn=<AddBackward0>)\n",
      "tensor(12217220., grad_fn=<AddBackward0>)\n",
      "tensor(12195439., grad_fn=<AddBackward0>)\n",
      "tensor(12173679., grad_fn=<AddBackward0>)\n",
      "tensor(12152001., grad_fn=<AddBackward0>)\n",
      "tensor(12130377., grad_fn=<AddBackward0>)\n",
      "tensor(12108796., grad_fn=<AddBackward0>)\n",
      "tensor(12087268., grad_fn=<AddBackward0>)\n",
      "tensor(12065793., grad_fn=<AddBackward0>)\n",
      "tensor(12044370., grad_fn=<AddBackward0>)\n",
      "tensor(12022998., grad_fn=<AddBackward0>)\n",
      "tensor(12001696., grad_fn=<AddBackward0>)\n",
      "tensor(11980405., grad_fn=<AddBackward0>)\n",
      "tensor(11959201., grad_fn=<AddBackward0>)\n",
      "tensor(11938035., grad_fn=<AddBackward0>)\n",
      "tensor(11916930., grad_fn=<AddBackward0>)\n",
      "tensor(11895891., grad_fn=<AddBackward0>)\n",
      "tensor(11874870., grad_fn=<AddBackward0>)\n",
      "tensor(11853909., grad_fn=<AddBackward0>)\n",
      "tensor(11833004., grad_fn=<AddBackward0>)\n",
      "tensor(11812162., grad_fn=<AddBackward0>)\n",
      "tensor(11791342., grad_fn=<AddBackward0>)\n",
      "tensor(11770609., grad_fn=<AddBackward0>)\n",
      "tensor(11749893., grad_fn=<AddBackward0>)\n",
      "tensor(11729247., grad_fn=<AddBackward0>)\n",
      "tensor(11708650., grad_fn=<AddBackward0>)\n",
      "tensor(11688094., grad_fn=<AddBackward0>)\n",
      "tensor(11667601., grad_fn=<AddBackward0>)\n",
      "tensor(11647164., grad_fn=<AddBackward0>)\n",
      "tensor(11626753., grad_fn=<AddBackward0>)\n",
      "tensor(11606404., grad_fn=<AddBackward0>)\n",
      "tensor(11586112., grad_fn=<AddBackward0>)\n",
      "tensor(11565853., grad_fn=<AddBackward0>)\n",
      "tensor(11545639., grad_fn=<AddBackward0>)\n",
      "tensor(11525490., grad_fn=<AddBackward0>)\n",
      "tensor(11505379., grad_fn=<AddBackward0>)\n",
      "tensor(11485322., grad_fn=<AddBackward0>)\n",
      "tensor(11465306., grad_fn=<AddBackward0>)\n",
      "tensor(11445356., grad_fn=<AddBackward0>)\n",
      "tensor(11425424., grad_fn=<AddBackward0>)\n",
      "tensor(11405562., grad_fn=<AddBackward0>)\n",
      "tensor(11385749., grad_fn=<AddBackward0>)\n",
      "tensor(11365984., grad_fn=<AddBackward0>)\n",
      "tensor(11346226., grad_fn=<AddBackward0>)\n",
      "tensor(11326539., grad_fn=<AddBackward0>)\n",
      "tensor(11306928., grad_fn=<AddBackward0>)\n",
      "tensor(11287323., grad_fn=<AddBackward0>)\n",
      "tensor(11267778., grad_fn=<AddBackward0>)\n",
      "tensor(11248282., grad_fn=<AddBackward0>)\n",
      "tensor(11228835., grad_fn=<AddBackward0>)\n",
      "tensor(11209415., grad_fn=<AddBackward0>)\n",
      "tensor(11190057., grad_fn=<AddBackward0>)\n",
      "tensor(11170748., grad_fn=<AddBackward0>)\n",
      "tensor(11151485., grad_fn=<AddBackward0>)\n",
      "tensor(11132255., grad_fn=<AddBackward0>)\n",
      "tensor(11113086., grad_fn=<AddBackward0>)\n",
      "tensor(11093950., grad_fn=<AddBackward0>)\n",
      "tensor(11074856., grad_fn=<AddBackward0>)\n",
      "tensor(11055818., grad_fn=<AddBackward0>)\n",
      "tensor(11036828., grad_fn=<AddBackward0>)\n",
      "tensor(11017877., grad_fn=<AddBackward0>)\n",
      "tensor(10998973., grad_fn=<AddBackward0>)\n",
      "tensor(10980124., grad_fn=<AddBackward0>)\n",
      "tensor(10961301., grad_fn=<AddBackward0>)\n",
      "tensor(10942549., grad_fn=<AddBackward0>)\n",
      "tensor(10923827., grad_fn=<AddBackward0>)\n",
      "tensor(10905139., grad_fn=<AddBackward0>)\n",
      "tensor(10886512., grad_fn=<AddBackward0>)\n",
      "tensor(10867928., grad_fn=<AddBackward0>)\n",
      "tensor(10849384., grad_fn=<AddBackward0>)\n",
      "tensor(10830884., grad_fn=<AddBackward0>)\n",
      "tensor(10812428., grad_fn=<AddBackward0>)\n",
      "tensor(10794010., grad_fn=<AddBackward0>)\n",
      "tensor(10775656., grad_fn=<AddBackward0>)\n",
      "tensor(10757338., grad_fn=<AddBackward0>)\n",
      "tensor(10739062., grad_fn=<AddBackward0>)\n",
      "tensor(10720823., grad_fn=<AddBackward0>)\n",
      "tensor(10702639., grad_fn=<AddBackward0>)\n",
      "tensor(10684485., grad_fn=<AddBackward0>)\n",
      "tensor(10666372., grad_fn=<AddBackward0>)\n",
      "tensor(10648310., grad_fn=<AddBackward0>)\n",
      "tensor(10630291., grad_fn=<AddBackward0>)\n",
      "tensor(10612320., grad_fn=<AddBackward0>)\n",
      "tensor(10594390., grad_fn=<AddBackward0>)\n",
      "tensor(10576492., grad_fn=<AddBackward0>)\n",
      "tensor(10558640., grad_fn=<AddBackward0>)\n",
      "tensor(10540842., grad_fn=<AddBackward0>)\n",
      "tensor(10523068., grad_fn=<AddBackward0>)\n",
      "tensor(10505345., grad_fn=<AddBackward0>)\n",
      "tensor(10487657., grad_fn=<AddBackward0>)\n",
      "tensor(10470021., grad_fn=<AddBackward0>)\n",
      "tensor(10452396., grad_fn=<AddBackward0>)\n",
      "tensor(10434834., grad_fn=<AddBackward0>)\n",
      "tensor(10417318., grad_fn=<AddBackward0>)\n",
      "tensor(10399834., grad_fn=<AddBackward0>)\n",
      "tensor(10382391., grad_fn=<AddBackward0>)\n",
      "tensor(10364977., grad_fn=<AddBackward0>)\n",
      "tensor(10347611., grad_fn=<AddBackward0>)\n",
      "tensor(10330293., grad_fn=<AddBackward0>)\n",
      "tensor(10313012., grad_fn=<AddBackward0>)\n",
      "tensor(10295772., grad_fn=<AddBackward0>)\n",
      "tensor(10278565., grad_fn=<AddBackward0>)\n",
      "tensor(10261403., grad_fn=<AddBackward0>)\n",
      "tensor(10244291., grad_fn=<AddBackward0>)\n",
      "tensor(10227210., grad_fn=<AddBackward0>)\n",
      "tensor(10210179., grad_fn=<AddBackward0>)\n",
      "tensor(10193162., grad_fn=<AddBackward0>)\n",
      "tensor(10176209., grad_fn=<AddBackward0>)\n",
      "tensor(10159300., grad_fn=<AddBackward0>)\n",
      "tensor(10142409., grad_fn=<AddBackward0>)\n",
      "tensor(10125560., grad_fn=<AddBackward0>)\n",
      "tensor(10108755., grad_fn=<AddBackward0>)\n",
      "tensor(10091996., grad_fn=<AddBackward0>)\n",
      "tensor(10075268., grad_fn=<AddBackward0>)\n",
      "tensor(10058570., grad_fn=<AddBackward0>)\n",
      "tensor(10041923., grad_fn=<AddBackward0>)\n",
      "tensor(10025316., grad_fn=<AddBackward0>)\n",
      "tensor(10008750., grad_fn=<AddBackward0>)\n",
      "tensor(9992208., grad_fn=<AddBackward0>)\n",
      "tensor(9975708., grad_fn=<AddBackward0>)\n",
      "tensor(9959236., grad_fn=<AddBackward0>)\n",
      "tensor(9942817., grad_fn=<AddBackward0>)\n",
      "tensor(9926427., grad_fn=<AddBackward0>)\n",
      "tensor(9910067., grad_fn=<AddBackward0>)\n",
      "tensor(9893757., grad_fn=<AddBackward0>)\n",
      "tensor(9877496., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m gen_features\u001b[38;5;241m=\u001b[39mmodel(generated_image)\n\u001b[0;32m      4\u001b[0m orig_feautes\u001b[38;5;241m=\u001b[39mmodel(original_image)\n\u001b[1;32m----> 5\u001b[0m style_featues\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstyle_image\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m total_loss\u001b[38;5;241m=\u001b[39mcalculate_loss(gen_features, orig_feautes, style_featues)\n\u001b[0;32m      9\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36mVGG.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      9\u001b[0m features\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer_num,layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel):\n\u001b[1;32m---> 11\u001b[0m     x\u001b[38;5;241m=\u001b[39m\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mstr\u001b[39m(layer_num) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreq_features):\n\u001b[0;32m     13\u001b[0m         features\u001b[38;5;241m.\u001b[39mappend(x)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    451\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    452\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Iterating for 1000 times\n",
    "for e in range (epoch):\n",
    "    gen_features=model(generated_image)\n",
    "    orig_feautes=model(original_image)\n",
    "    style_featues=model(style_image)\n",
    "    \n",
    "\n",
    "    total_loss=calculate_loss(gen_features, orig_feautes, style_featues)\n",
    "    optimizer.zero_grad()\n",
    "    total_loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if(e/100):\n",
    "        print(total_loss)\n",
    "        \n",
    "        save_image(generated_image,\"Bataan_Fernando_Amorsolo.png\")    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
